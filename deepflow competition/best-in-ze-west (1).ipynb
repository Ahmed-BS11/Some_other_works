{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nimport re \nimport json\nimport xgboost as xgb\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.linear_model import Ridge\n\nle = LabelEncoder()\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_selection import SelectKBest, f_regression\nfrom scipy import stats\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-08T08:57:20.302900Z","iopub.execute_input":"2023-05-08T08:57:20.303409Z","iopub.status.idle":"2023-05-08T08:57:20.311289Z","shell.execute_reply.started":"2023-05-08T08:57:20.303356Z","shell.execute_reply":"2023-05-08T08:57:20.309721Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess(data):\n    # Replace single quotes with double quotes in \"random load mesures\" column\n    data[\"random load mesures\"] = data[\"random load mesures\"].str.replace(\"'\",'\"')\n    data['building'] = data['building'].str.replace('Building_',\"\").astype(int)\n    data['Town'] = le.fit_transform(data['Town'])\n    data['Total Wall Area'] = data['Wall Rt'] * data['Height'] * data['Number of Floors']\n    #data['Total Window Area'] = data['Windows Rt'] * data['Height'] * data['WWR'] * data['Number of Floors']\n    data['Total Floor Area'] = data['Ground Floor Rt'] * data['Height']\n    data['Total Roof Area'] = data['Roof Rt'] * data['Height']\n    data['Total Internal Wall Area'] = data['Internal Wall Rt'] * data['Height'] * data['Number of Floors']\n    data['Total Internal Floor Area'] = data['Internal Floor Rt'] * data['Height']\n    data['Overall Energy Consumption'] = data['Operating Hours'] * data['EUI']\n\n    \n    pattern = r'\\d+\\.\\d+'\n    wwr = data['WWR'].apply(lambda x: max([float(m) for m in re.findall(pattern, x)]))\n    data['WWR'] = wwr\n    # assuming 'File' contains unique file names for each building shape, it can be removed\n    \n    \n    features = data['random load mesures'].apply(lambda x: json.loads(x))\n    cooling = features.apply(lambda x: float(x['Cooling'].replace(\":C\",\"\")))\n    lights = features.apply(lambda x: float(x['Lights'].replace(\":C\",\"\")))\n    data['Coolings'] = cooling\n    data['Lights'] = lights\n    \n    data['Lighting Impact on Heat Load'] = data['Lights'] * data['Light Heat Gain']\n    data['Energy Efficiency'] = data['EUI'] / data['Number of Floors']\n    data['Lighting Heat Addition Rate'] = data['Light Heat Gain'] / data['Operating Hours']\n    \n\n    scaler = StandardScaler()\n    data[['Cooling Setpoint','Coolings','Lights', 'EUI', 'Cooling COP', 'Operating Hours', 'WWR',      'Equipment Heat Gain', 'Internal Wall Rt', 'Internal Floor Rt', 'Infiltration','Ground Floor Rt', 'Number of Floors', 'Occupancy', 'Light Heat Gain', 'Windows Rt',      'Height', 'Heating COP', 'Heating Setpoint', 'Wall Rt', 'Start Time', 'windows g-value',      'Roof Rt', 'Boiler Efficiency', 'Internal Mass', 'Permeability', 'Total Floors Area',]] = scaler.fit_transform(data[['Cooling Setpoint','Coolings','Lights', 'EUI', 'Cooling COP', 'Operating Hours', 'WWR',                                                              'Equipment Heat Gain', 'Internal Wall Rt', 'Internal Floor Rt', 'Infiltration',                                                              'Ground Floor Rt', 'Number of Floors', 'Occupancy', 'Light Heat Gain', 'Windows Rt',                                                              'Height', 'Heating COP', 'Heating Setpoint', 'Wall Rt', 'Start Time', 'windows g-value',                                                              'Roof Rt', 'Boiler Efficiency', 'Internal Mass', 'Permeability', 'Total Floors Area']])\n    \n    interaction_features = ['Overall Energy Consumption', 'Lighting Impact on Heat Load', 'Energy Efficiency','Lighting Heat Addition Rate']\n    for feature1 in interaction_features:\n        for feature2 in interaction_features:\n            if feature1 != feature2:\n                interaction_feature_name = f'{feature1} x {feature2}'\n                data[interaction_feature_name] = data[feature1] * data[feature2]\n\n    # assuming we want to select the top 10 features with the highest F-test score\n    selector = SelectKBest(f_regression, k=10)\n    data = data.drop(['random load mesures', 'Permeability','File'], axis=1)\n    #data = selector.fit_transform(data.drop('Operational Energy', axis=1), data['Operational Energy'])\n    # assume your data is stored in a NumPy array called `data`\n    for col in data.columns:\n        if col == 'Operational Energy':\n            continue  # skip target variable\n        median = np.median(data[col])\n        q1 = np.percentile(data[col], 25)\n        q3 = np.percentile(data[col], 75)\n        iqr = q3 - q1\n        upper_bound = q3 + 1.5 * iqr\n        lower_bound = q1 - 1.5 * iqr\n        data.loc[data[col] > upper_bound, col] = median\n        data.loc[data[col] < lower_bound, col] = median\n\n    return data\n","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:57:20.313688Z","iopub.execute_input":"2023-05-08T08:57:20.314561Z","iopub.status.idle":"2023-05-08T08:57:20.333377Z","shell.execute_reply.started":"2023-05-08T08:57:20.314515Z","shell.execute_reply":"2023-05-08T08:57:20.332464Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train=pd.read_csv(\"/kaggle/input/traintrain/Train.csv\")\ntest = pd.read_csv(\"/kaggle/input/testing/Test (1).csv\")\ncsv_file = pd.DataFrame()\ncsv_file['submission id'] = test['building'] + '_Town_' + test['Town'].astype(str)\n\ncsv_file.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:57:20.334599Z","iopub.execute_input":"2023-05-08T08:57:20.335592Z","iopub.status.idle":"2023-05-08T08:57:21.186835Z","shell.execute_reply.started":"2023-05-08T08:57:20.335557Z","shell.execute_reply":"2023-05-08T08:57:21.186005Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"           submission id\n0      Building_1_Town_1\n1    Building_100_Town_1\n2   Building_1000_Town_2\n3  Building_10000_Town_0\n4  Building_10005_Town_2","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>submission id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Building_1_Town_1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Building_100_Town_1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Building_1000_Town_2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Building_10000_Town_0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Building_10005_Town_2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Preprocess train and test data\ntrain = preprocess(train)\ntest = preprocess(test)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:57:21.188873Z","iopub.execute_input":"2023-05-08T08:57:21.189614Z","iopub.status.idle":"2023-05-08T08:57:22.465422Z","shell.execute_reply.started":"2023-05-08T08:57:21.189577Z","shell.execute_reply":"2023-05-08T08:57:22.464222Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from catboost import CatBoostRegressor\n\n\ncatboost_model = CatBoostRegressor()\n\nX = train.drop(['Operational Energy'], axis=1)\ny = train['Operational Energy']\nn_folds = 5\nkf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n\n# Initialize the list to store the mean squared errors (MSEs)\nmse_list = []","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:57:22.467038Z","iopub.execute_input":"2023-05-08T08:57:22.467380Z","iopub.status.idle":"2023-05-08T08:57:22.487229Z","shell.execute_reply.started":"2023-05-08T08:57:22.467351Z","shell.execute_reply":"2023-05-08T08:57:22.486051Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfor train_index, val_index in kf.split(X):\n    \n    # Split the data into training and validation sets\n    X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n    \n    # Scale the data using StandardScaler\n    scaler = StandardScaler()\n    X_train_fold_scaled = scaler.fit_transform(X_train_fold)\n    X_val_fold_scaled = scaler.transform(X_val_fold)\n    \n    # Apply PCA to reduce dimensionality\n    pca = PCA(n_components=10)\n    X_train_fold_pca = pca.fit_transform(X_train_fold_scaled)\n    X_val_fold_pca = pca.transform(X_val_fold_scaled)\n    alpha = 0.1  # regularization strength\n    model=LinearRegression()\n    model = Ridge(alpha=alpha)\n    # Train the model\n    model.fit(X_train_fold_pca, y_train_fold)\n    \n    # Make predictions on the validation set and calculate MSE\n    y_pred = model.predict(X_val_fold_pca)\n    mse = np.mean((y_val_fold - y_pred)**2)\n    \n    # Append the MSE to the list\n    mse_list.append(mse)\n    \n# Print the mean of the MSEs\nprint(\"Mean MSE:\", np.mean(mse_list))","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:57:22.490394Z","iopub.execute_input":"2023-05-08T08:57:22.491473Z","iopub.status.idle":"2023-05-08T08:57:25.154166Z","shell.execute_reply.started":"2023-05-08T08:57:22.491438Z","shell.execute_reply":"2023-05-08T08:57:25.152562Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Mean MSE: 1616406272.178697\n","output_type":"stream"}]},{"cell_type":"code","source":"y_4b=scaler.fit_transform(test)\ny_4b=pca.transform(y_4b)\ny_4b = model.predict(y_4b)\ny_4b","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:57:25.157007Z","iopub.execute_input":"2023-05-08T08:57:25.159008Z","iopub.status.idle":"2023-05-08T08:57:25.227126Z","shell.execute_reply.started":"2023-05-08T08:57:25.158953Z","shell.execute_reply":"2023-05-08T08:57:25.225696Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"array([ 89313.39338672,  98883.8728327 , 100550.19671778, ...,\n       187989.57381425,  49419.13424275, 199207.69700204])"},"metadata":{}}]},{"cell_type":"code","source":"importances = model.coef_\n\n# Sort feature importances in descending order\nsorted_importances = sorted(zip(importances, X.columns), reverse=True)\n\n# Print the feature importances\nfor importance, feature in sorted_importances:\n    print(f\"{feature}: {importance}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:57:25.229443Z","iopub.execute_input":"2023-05-08T08:57:25.230573Z","iopub.status.idle":"2023-05-08T08:57:25.244418Z","shell.execute_reply.started":"2023-05-08T08:57:25.230517Z","shell.execute_reply":"2023-05-08T08:57:25.239920Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"EUI: 14262.681143365577\nCooling Setpoint: 12831.472406418443\nbuilding: 8540.112074341316\nInfiltration: 8114.643836539316\nEquipment Heat Gain: 3099.6441584998656\nOperating Hours: -387.8323671454449\nCooling COP: -1287.6778978670993\nWWR: -1588.445944124592\nInternal Wall Rt: -4535.907759753471\nInternal Floor Rt: -4812.043440061067\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#importance_scores = catboost_model.feature_importances_\nfeature_importances = dict(zip(X.columns, sorted_importances))\ntop_8_features = sorted(feature_importances, key=feature_importances.get, reverse=True)[:8]\nfrom sklearn.linear_model import LinearRegression\n# Select only the top 5 features\nX = X[top_8_features]\ntest = test[top_8_features]\n\n# Set up the KFold object\nn_folds = 5\nkf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n\n# Initialize the list to store the mean squared errors (MSEs)\nmse_list = []\n\n# Loop over the folds\nfor train_index, val_index in kf.split(X):\n    \n    # Split the data into training and validation sets\n    X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n\n    # Scale the features\n    scaler = StandardScaler()\n    X_train_fold = scaler.fit_transform(X_train_fold)\n    X_val_fold = scaler.transform(X_val_fold)\n    \n    # Reduce dimensionality using PCA\n    pca = PCA(n_components=2)\n    X_train_fold = pca.fit_transform(X_train_fold)\n    X_val_fold = pca.transform(X_val_fold)\n\n    # Train the model and predict on the validation set\n    model=LinearRegression()\n    model.fit(X_train_fold, y_train_fold)\n    y_pred = model.predict(X_val_fold)\n\n    # Compute the mean squared error\n    mse = np.mean((y_val_fold - y_pred)**2)\n    mse_list.append(mse)\n\n# Compute the average mean squared error over the folds\navg_mse = np.min(mse_list)\nprint(\"Average MSE:\", avg_mse)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:57:25.247329Z","iopub.execute_input":"2023-05-08T08:57:25.253322Z","iopub.status.idle":"2023-05-08T08:57:26.033457Z","shell.execute_reply.started":"2023-05-08T08:57:25.253250Z","shell.execute_reply":"2023-05-08T08:57:26.031676Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Average MSE: 3917445253.5085816\n","output_type":"stream"}]},{"cell_type":"code","source":"avg_mse = np.max(mse_list)\nprint(\"Average MSE:\", avg_mse)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:57:26.044302Z","iopub.execute_input":"2023-05-08T08:57:26.049743Z","iopub.status.idle":"2023-05-08T08:57:26.062473Z","shell.execute_reply.started":"2023-05-08T08:57:26.049666Z","shell.execute_reply":"2023-05-08T08:57:26.061178Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Average MSE: 4001749311.664489\n","output_type":"stream"}]},{"cell_type":"code","source":"y_4bb=scaler.fit_transform(test)\ny_4bb=pca.transform(y_4bb)\ny_4bb = model.predict(y_4bb)\ny_4bb","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:57:26.064378Z","iopub.execute_input":"2023-05-08T08:57:26.065117Z","iopub.status.idle":"2023-05-08T08:57:26.086846Z","shell.execute_reply.started":"2023-05-08T08:57:26.065077Z","shell.execute_reply":"2023-05-08T08:57:26.085668Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"array([169336.68158218, 138645.20800702, 178984.1696174 , ...,\n       196738.27499202, 142545.58650617, 209757.49988912])"},"metadata":{}}]},{"cell_type":"code","source":"#csv_file=pd.read_csv(\"/kaggle/input/simple/SampleSubmiss\n    \ncsv_file['Operational Energy']=y_4bb.astype(int)\n\ncsv_file.to_csv(\"labidi1551.csv\",index=False)\ntype(csv_file['Operational Energy'][0])","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:58:07.599018Z","iopub.execute_input":"2023-05-08T08:58:07.599420Z","iopub.status.idle":"2023-05-08T08:58:07.650890Z","shell.execute_reply.started":"2023-05-08T08:58:07.599388Z","shell.execute_reply":"2023-05-08T08:58:07.649821Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"numpy.int64"},"metadata":{}}]},{"cell_type":"code","source":"csv_file.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:58:10.002489Z","iopub.execute_input":"2023-05-08T08:58:10.002970Z","iopub.status.idle":"2023-05-08T08:58:10.014295Z","shell.execute_reply.started":"2023-05-08T08:58:10.002932Z","shell.execute_reply":"2023-05-08T08:58:10.013102Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"           submission id  Operational Energy\n0      Building_1_Town_1              169336\n1    Building_100_Town_1              138645\n2   Building_1000_Town_2              178984\n3  Building_10000_Town_0              184816\n4  Building_10005_Town_2              167148","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>submission id</th>\n      <th>Operational Energy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Building_1_Town_1</td>\n      <td>169336</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Building_100_Town_1</td>\n      <td>138645</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Building_1000_Town_2</td>\n      <td>178984</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Building_10000_Town_0</td>\n      <td>184816</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Building_10005_Town_2</td>\n      <td>167148</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}