{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-08T08:38:19.988507Z","iopub.execute_input":"2023-05-08T08:38:19.988965Z","iopub.status.idle":"2023-05-08T08:38:19.994437Z","shell.execute_reply.started":"2023-05-08T08:38:19.988929Z","shell.execute_reply":"2023-05-08T08:38:19.993359Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"train=pd.read_csv(\"/kaggle/input/traintrain/Train.csv\")\ntest = pd.read_csv(\"/kaggle/input/testtest/Test (2).csv\")\ncsv_file = pd.DataFrame()\ncsv_file['submission id'] = test['building'] + '_Town_' + test['Town'].astype(str)\n\ncsv_file.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:43:14.747985Z","iopub.execute_input":"2023-05-08T08:43:14.748502Z","iopub.status.idle":"2023-05-08T08:43:15.828793Z","shell.execute_reply.started":"2023-05-08T08:43:14.748449Z","shell.execute_reply":"2023-05-08T08:43:15.827985Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"           submission id\n0      Building_1_Town_1\n1    Building_100_Town_1\n2   Building_1000_Town_2\n3  Building_10000_Town_0\n4  Building_10005_Town_2","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>submission id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Building_1_Town_1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Building_100_Town_1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Building_1000_Town_2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Building_10000_Town_0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Building_10005_Town_2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"\ntrain[\"random load mesures\"] = train[\"random load mesures\"].str.replace(\"'\",'\"')\ntest[\"random load mesures\"] = test[\"random load mesures\"].str.replace(\"'\",'\"')","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:43:21.683718Z","iopub.execute_input":"2023-05-08T08:43:21.684200Z","iopub.status.idle":"2023-05-08T08:43:21.736287Z","shell.execute_reply.started":"2023-05-08T08:43:21.684167Z","shell.execute_reply":"2023-05-08T08:43:21.735226Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"train['building'] = train['building'].str.replace(\"Building_\",\"\")\ntrain['building'] = train['building'].astype(int)\ntrain['File'] = train['File'].str.replace(\"Shape0_\",\"\")\ntrain['File'] = train['File'].astype(int)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:43:22.126648Z","iopub.execute_input":"2023-05-08T08:43:22.127989Z","iopub.status.idle":"2023-05-08T08:43:22.232812Z","shell.execute_reply.started":"2023-05-08T08:43:22.127946Z","shell.execute_reply":"2023-05-08T08:43:22.231662Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"test['building'] = test['building'].str.replace(\"Building_\",\"\")\ntest['building'] = test['building'].astype(int)\ntest['File'] = test['File'].str.replace(\"Shape0_\",\"\")\ntest['File'] = test['File'].astype(int)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:43:22.485162Z","iopub.execute_input":"2023-05-08T08:43:22.485727Z","iopub.status.idle":"2023-05-08T08:43:22.537009Z","shell.execute_reply.started":"2023-05-08T08:43:22.485679Z","shell.execute_reply":"2023-05-08T08:43:22.535930Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"import re \naddress = train['WWR']\nWWR = []\nfor i in address :\n    values = re.findall(r'\\d+\\.\\d+',i)\n    float_value = [float(value) for value in values]\n    maxi = max(float_value)\n    WWR.append(maxi)\ntrain['WWR']= WWR","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:43:22.811543Z","iopub.execute_input":"2023-05-08T08:43:22.812008Z","iopub.status.idle":"2023-05-08T08:43:23.041570Z","shell.execute_reply.started":"2023-05-08T08:43:22.811973Z","shell.execute_reply":"2023-05-08T08:43:23.040034Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"import re \naddress2 = test['WWR']\nWWR = []\nfor i in address2 :\n    values = re.findall(r'\\d+\\.\\d+',i)\n    float_value = [float(value) for value in values]\n    maxi = max(float_value)\n    WWR.append(maxi)\ntest['WWR']= WWR","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:43:23.131894Z","iopub.execute_input":"2023-05-08T08:43:23.132292Z","iopub.status.idle":"2023-05-08T08:43:23.238894Z","shell.execute_reply.started":"2023-05-08T08:43:23.132260Z","shell.execute_reply":"2023-05-08T08:43:23.237770Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"import json\ncooling = []\nlights = []\nn=train.shape[0]\n# loop through the dataset\nfor i in range(n):\n    # extract the feature value (which is a dictionary)\n    feature_value = train['random load mesures'][i]\n    #print(feature_value)\n    feature=json.loads(feature_value)\n    values_list = list(feature.values())\n    # extract the values for Cooling and Lights from the dictionary\n    cooling_value = float(values_list[0].replace(\":C\",\"\"))\n    lights_value = float(values_list[1].replace(\":C\",\"\"))\n    \n    # add the values to the corresponding lists\n    cooling.append(cooling_value)\n    lights.append(lights_value)\n    \n# print the two l\n\ntrain[\"Coolings\"]=cooling\ntrain[\"Lights\"]=lights","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:43:23.478464Z","iopub.execute_input":"2023-05-08T08:43:23.479650Z","iopub.status.idle":"2023-05-08T08:43:24.133303Z","shell.execute_reply.started":"2023-05-08T08:43:23.479598Z","shell.execute_reply":"2023-05-08T08:43:24.131712Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"\ncooling2 = []\nlights2 = []\nn2=test.shape[0]\n# loop through the dataset\nfor i in range(n2):\n    # extract the feature value (which is a dictionary)\n    feature_value2 = test['random load mesures'][i]\n    #print(feature_value)\n    feature2=json.loads(feature_value2)\n    values_list2 = list(feature2.values())\n    # extract the values for Cooling and Lights from the dictionary\n    cooling_value2 = float(values_list2[0].replace(\":C\",\"\"))\n    lights_value2 = float(values_list2[1].replace(\":C\",\"\"))\n    \n    # add the values to the corresponding lists\n    cooling2.append(cooling_value2)\n    lights2.append(lights_value2)\n    \n# print the two l\n\ntest[\"Coolings\"]=cooling2\ntest[\"Lights\"]=lights2","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:43:24.135461Z","iopub.execute_input":"2023-05-08T08:43:24.135891Z","iopub.status.idle":"2023-05-08T08:43:24.428856Z","shell.execute_reply.started":"2023-05-08T08:43:24.135857Z","shell.execute_reply":"2023-05-08T08:43:24.427367Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"train=train.drop('random load mesures', axis=1)\ntrain=train.drop(['Permeability'], axis=1)\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:43:24.431460Z","iopub.execute_input":"2023-05-08T08:43:24.432401Z","iopub.status.idle":"2023-05-08T08:43:24.474700Z","shell.execute_reply.started":"2023-05-08T08:43:24.432348Z","shell.execute_reply":"2023-05-08T08:43:24.473393Z"},"trusted":true},"execution_count":50,"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"   building   File  Cooling Setpoint        EUI  Cooling COP  Operating Hours  \\\n0         0  10851         26.804565  37.155511     4.430542        12.166667   \n1        10  11866         25.219604  64.131327     2.855347         9.166667   \n2     10001  15816         26.691040  31.992473     2.863892        10.166667   \n3     10002  15566         25.468384  40.932114     3.922485        10.333333   \n4     10003   3155         25.152832  57.792356     2.828613        10.833333   \n\n        WWR  Equipment Heat Gain  Internal Wall Rt  Internal Floor Rt  ...  \\\n0  0.771637            15.463379          2.511920           1.919918  ...   \n1  0.831842            11.646973          2.080851           2.822443  ...   \n2  0.695172             9.899902          2.274071           2.341140  ...   \n3  0.924347            12.196777          2.541613           2.390324  ...   \n4  0.449683            12.552734          1.586183           2.228146  ...   \n\n    Wall Rt  Start Time  windows g-value   Roof Rt  Boiler Efficiency  \\\n0  4.640045    8.778931         0.381354  2.912090           0.921890   \n1  3.621094    8.131470         0.556696  4.019824           0.908726   \n2  4.595792    7.406128         0.572552  5.745949           0.911157   \n3  5.310859    7.831909         0.520404  4.394614           0.929751   \n4  4.190710    8.794434         0.475854  5.271557           0.947480   \n\n   Internal Mass  Total Floors Area  Operational Energy      Coolings  \\\n0      44.441528           18210.25       135322.229618   6743.000738   \n1      41.702271           13110.25       168155.546796   6485.849597   \n2      24.244995           13561.60       108467.281862   3861.976104   \n3      24.655151           21678.00       177465.271945  10788.092245   \n4      29.201660           14200.16       205165.175932   4314.221007   \n\n         Lights  \n0  10475.824219  \n1   3108.639378  \n2   4866.355447  \n3   7679.311052  \n4   5904.960314  \n\n[5 rows x 30 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>building</th>\n      <th>File</th>\n      <th>Cooling Setpoint</th>\n      <th>EUI</th>\n      <th>Cooling COP</th>\n      <th>Operating Hours</th>\n      <th>WWR</th>\n      <th>Equipment Heat Gain</th>\n      <th>Internal Wall Rt</th>\n      <th>Internal Floor Rt</th>\n      <th>...</th>\n      <th>Wall Rt</th>\n      <th>Start Time</th>\n      <th>windows g-value</th>\n      <th>Roof Rt</th>\n      <th>Boiler Efficiency</th>\n      <th>Internal Mass</th>\n      <th>Total Floors Area</th>\n      <th>Operational Energy</th>\n      <th>Coolings</th>\n      <th>Lights</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>10851</td>\n      <td>26.804565</td>\n      <td>37.155511</td>\n      <td>4.430542</td>\n      <td>12.166667</td>\n      <td>0.771637</td>\n      <td>15.463379</td>\n      <td>2.511920</td>\n      <td>1.919918</td>\n      <td>...</td>\n      <td>4.640045</td>\n      <td>8.778931</td>\n      <td>0.381354</td>\n      <td>2.912090</td>\n      <td>0.921890</td>\n      <td>44.441528</td>\n      <td>18210.25</td>\n      <td>135322.229618</td>\n      <td>6743.000738</td>\n      <td>10475.824219</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10</td>\n      <td>11866</td>\n      <td>25.219604</td>\n      <td>64.131327</td>\n      <td>2.855347</td>\n      <td>9.166667</td>\n      <td>0.831842</td>\n      <td>11.646973</td>\n      <td>2.080851</td>\n      <td>2.822443</td>\n      <td>...</td>\n      <td>3.621094</td>\n      <td>8.131470</td>\n      <td>0.556696</td>\n      <td>4.019824</td>\n      <td>0.908726</td>\n      <td>41.702271</td>\n      <td>13110.25</td>\n      <td>168155.546796</td>\n      <td>6485.849597</td>\n      <td>3108.639378</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10001</td>\n      <td>15816</td>\n      <td>26.691040</td>\n      <td>31.992473</td>\n      <td>2.863892</td>\n      <td>10.166667</td>\n      <td>0.695172</td>\n      <td>9.899902</td>\n      <td>2.274071</td>\n      <td>2.341140</td>\n      <td>...</td>\n      <td>4.595792</td>\n      <td>7.406128</td>\n      <td>0.572552</td>\n      <td>5.745949</td>\n      <td>0.911157</td>\n      <td>24.244995</td>\n      <td>13561.60</td>\n      <td>108467.281862</td>\n      <td>3861.976104</td>\n      <td>4866.355447</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10002</td>\n      <td>15566</td>\n      <td>25.468384</td>\n      <td>40.932114</td>\n      <td>3.922485</td>\n      <td>10.333333</td>\n      <td>0.924347</td>\n      <td>12.196777</td>\n      <td>2.541613</td>\n      <td>2.390324</td>\n      <td>...</td>\n      <td>5.310859</td>\n      <td>7.831909</td>\n      <td>0.520404</td>\n      <td>4.394614</td>\n      <td>0.929751</td>\n      <td>24.655151</td>\n      <td>21678.00</td>\n      <td>177465.271945</td>\n      <td>10788.092245</td>\n      <td>7679.311052</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10003</td>\n      <td>3155</td>\n      <td>25.152832</td>\n      <td>57.792356</td>\n      <td>2.828613</td>\n      <td>10.833333</td>\n      <td>0.449683</td>\n      <td>12.552734</td>\n      <td>1.586183</td>\n      <td>2.228146</td>\n      <td>...</td>\n      <td>4.190710</td>\n      <td>8.794434</td>\n      <td>0.475854</td>\n      <td>5.271557</td>\n      <td>0.947480</td>\n      <td>29.201660</td>\n      <td>14200.16</td>\n      <td>205165.175932</td>\n      <td>4314.221007</td>\n      <td>5904.960314</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 30 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test=test.drop('random load mesures', axis=1)\ntest=test.drop(['Permeability'], axis=1)\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:43:24.720089Z","iopub.execute_input":"2023-05-08T08:43:24.720626Z","iopub.status.idle":"2023-05-08T08:43:24.753732Z","shell.execute_reply.started":"2023-05-08T08:43:24.720589Z","shell.execute_reply":"2023-05-08T08:43:24.752456Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"   building  File  Cooling Setpoint        EUI  Cooling COP  Operating Hours  \\\n0         1  6003         25.371338  48.450552     2.972900        12.000000   \n1       100   369         25.034217  39.219867     3.983462         9.166667   \n2      1000   632         25.173828  62.887801     2.736328        12.166667   \n3     10000  7548         25.193115  69.128493     4.458740        13.333333   \n4     10005   934         25.254967  52.557239     3.002524         9.000000   \n\n        WWR  Equipment Heat Gain  Internal Wall Rt  Internal Floor Rt  ...  \\\n0  0.693250            10.346680          2.298476           1.580948  ...   \n1  0.911371            14.214766          1.941513           2.070646  ...   \n2  0.922754            13.398438          1.817859           2.191312  ...   \n3  0.942639            11.625977          1.846750           2.535359  ...   \n4  0.803705             9.034523          2.308631           1.987770  ...   \n\n   Town   Wall Rt  Start Time  windows g-value   Roof Rt  Boiler Efficiency  \\\n0     1  3.674531    7.916260         0.387854  4.349581           0.905850   \n1     1  6.259573    7.043643         0.395789  3.625850           0.963632   \n2     2  5.350052    8.642578         0.529980  6.555698           0.938828   \n3     0  6.375097    8.576904         0.392322  3.280211           0.979033   \n4     2  3.249097    8.190305         0.506399  6.460178           0.906366   \n\n   Internal Mass  Total Floors Area      Coolings        Lights  \n0      24.708252            4523.94   1643.835083   3572.205207  \n1      25.543847           10876.48   5289.278461   3745.388416  \n2      27.744141            4232.25   4704.196187   2168.565232  \n3      42.161865           29940.12   9207.803908  15335.973400  \n4      19.061121           27435.24  10630.388797   7779.813996  \n\n[5 rows x 29 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>building</th>\n      <th>File</th>\n      <th>Cooling Setpoint</th>\n      <th>EUI</th>\n      <th>Cooling COP</th>\n      <th>Operating Hours</th>\n      <th>WWR</th>\n      <th>Equipment Heat Gain</th>\n      <th>Internal Wall Rt</th>\n      <th>Internal Floor Rt</th>\n      <th>...</th>\n      <th>Town</th>\n      <th>Wall Rt</th>\n      <th>Start Time</th>\n      <th>windows g-value</th>\n      <th>Roof Rt</th>\n      <th>Boiler Efficiency</th>\n      <th>Internal Mass</th>\n      <th>Total Floors Area</th>\n      <th>Coolings</th>\n      <th>Lights</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>6003</td>\n      <td>25.371338</td>\n      <td>48.450552</td>\n      <td>2.972900</td>\n      <td>12.000000</td>\n      <td>0.693250</td>\n      <td>10.346680</td>\n      <td>2.298476</td>\n      <td>1.580948</td>\n      <td>...</td>\n      <td>1</td>\n      <td>3.674531</td>\n      <td>7.916260</td>\n      <td>0.387854</td>\n      <td>4.349581</td>\n      <td>0.905850</td>\n      <td>24.708252</td>\n      <td>4523.94</td>\n      <td>1643.835083</td>\n      <td>3572.205207</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100</td>\n      <td>369</td>\n      <td>25.034217</td>\n      <td>39.219867</td>\n      <td>3.983462</td>\n      <td>9.166667</td>\n      <td>0.911371</td>\n      <td>14.214766</td>\n      <td>1.941513</td>\n      <td>2.070646</td>\n      <td>...</td>\n      <td>1</td>\n      <td>6.259573</td>\n      <td>7.043643</td>\n      <td>0.395789</td>\n      <td>3.625850</td>\n      <td>0.963632</td>\n      <td>25.543847</td>\n      <td>10876.48</td>\n      <td>5289.278461</td>\n      <td>3745.388416</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1000</td>\n      <td>632</td>\n      <td>25.173828</td>\n      <td>62.887801</td>\n      <td>2.736328</td>\n      <td>12.166667</td>\n      <td>0.922754</td>\n      <td>13.398438</td>\n      <td>1.817859</td>\n      <td>2.191312</td>\n      <td>...</td>\n      <td>2</td>\n      <td>5.350052</td>\n      <td>8.642578</td>\n      <td>0.529980</td>\n      <td>6.555698</td>\n      <td>0.938828</td>\n      <td>27.744141</td>\n      <td>4232.25</td>\n      <td>4704.196187</td>\n      <td>2168.565232</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10000</td>\n      <td>7548</td>\n      <td>25.193115</td>\n      <td>69.128493</td>\n      <td>4.458740</td>\n      <td>13.333333</td>\n      <td>0.942639</td>\n      <td>11.625977</td>\n      <td>1.846750</td>\n      <td>2.535359</td>\n      <td>...</td>\n      <td>0</td>\n      <td>6.375097</td>\n      <td>8.576904</td>\n      <td>0.392322</td>\n      <td>3.280211</td>\n      <td>0.979033</td>\n      <td>42.161865</td>\n      <td>29940.12</td>\n      <td>9207.803908</td>\n      <td>15335.973400</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10005</td>\n      <td>934</td>\n      <td>25.254967</td>\n      <td>52.557239</td>\n      <td>3.002524</td>\n      <td>9.000000</td>\n      <td>0.803705</td>\n      <td>9.034523</td>\n      <td>2.308631</td>\n      <td>1.987770</td>\n      <td>...</td>\n      <td>2</td>\n      <td>3.249097</td>\n      <td>8.190305</td>\n      <td>0.506399</td>\n      <td>6.460178</td>\n      <td>0.906366</td>\n      <td>19.061121</td>\n      <td>27435.24</td>\n      <td>10630.388797</td>\n      <td>7779.813996</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 29 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X = train.drop(['Operational Energy'], axis=1)\ny = train['Operational Energy']\ny=y.values.reshape(-1,1)\n# Standardize the data\nscaler = StandardScaler()\nscaled_train = scaler.fit_transform(X)\nscaled_y=scaler.fit_transform(y)\n# Apply PCA\n\"\"\"n_components = 10\npca = PCA(n_components=n_components)\npca.fit(scaled_train)\npca.fit(scaled_y)\nX_fold = pca.fit_transform(scaled_train)\n\n# Transform the data\nscaled_train.shape\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:43:25.294022Z","iopub.execute_input":"2023-05-08T08:43:25.294514Z","iopub.status.idle":"2023-05-08T08:43:25.366521Z","shell.execute_reply.started":"2023-05-08T08:43:25.294452Z","shell.execute_reply":"2023-05-08T08:43:25.365182Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"'n_components = 10\\npca = PCA(n_components=n_components)\\npca.fit(scaled_train)\\npca.fit(scaled_y)\\nX_fold = pca.fit_transform(scaled_train)\\n\\n# Transform the data\\nscaled_train.shape\\n'"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\n# Load the data into a Pandas DataFrame\nnew_arr = np.delete(scaled_train, 28, axis=1)\nnew_y=scaled_train[:, 28]\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(new_arr, new_y, test_size=0.2, random_state=42)\n\n# Create the decision tree regressor model\ndt = DecisionTreeRegressor(max_depth=10, random_state=42)\n\n# Fit the model to the training data\ndt.fit(X_train, y_train)\n\n# Predict the operational energy values for the testing data\ny_pred = dt.predict(X_test)\n\n# Calculate the root mean squared error of the predictions\nrmse = mean_squared_error(y_test, y_pred)\n\nprint(\"Decision Tree RMSE: \", rmse)\ny_test","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:43:25.832312Z","iopub.execute_input":"2023-05-08T08:43:25.833314Z","iopub.status.idle":"2023-05-08T08:43:26.876115Z","shell.execute_reply.started":"2023-05-08T08:43:25.833243Z","shell.execute_reply":"2023-05-08T08:43:26.874675Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"Decision Tree RMSE:  0.022590092508609532\n","output_type":"stream"},{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"array([-0.66981932, -0.22356922,  1.23716021, ..., -1.38499918,\n       -0.40259114,  1.54455582])"},"metadata":{}}]},{"cell_type":"code","source":"scaled_test=scaler.fit_transform(test)\nscaled_test=np.delete(scaled_test, 28, axis=1)\ny_pred_scaled = dt.predict(scaled_test)\n\nt_pred = y_pred_scaled * (max(y_pred_scaled) - min(y_pred_scaled)) + min(y_pred_scaled)\n\nt_pred\n#y_pred = scaler.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()\nmini=32780.873847\nmaxi=423444.390589\n\ndiff=maxi-mini\n\n#rescaled_t_pred=[x*diff+mini for x in t_pred]\nrescaled_t_pred=[abs(x) for x in rescaled_t_pred]\n#rescaled_t_pred","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:46:23.436044Z","iopub.execute_input":"2023-05-08T08:46:23.436417Z","iopub.status.idle":"2023-05-08T08:46:23.620184Z","shell.execute_reply.started":"2023-05-08T08:46:23.436389Z","shell.execute_reply":"2023-05-08T08:46:23.618217Z"},"trusted":true},"execution_count":65,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[65], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m t_pred \u001b[38;5;241m=\u001b[39m y_pred_scaled \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mmax\u001b[39m(y_pred_scaled) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mmin\u001b[39m(y_pred_scaled)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mmin\u001b[39m(y_pred_scaled)\n\u001b[1;32m      7\u001b[0m t_pred\n\u001b[0;32m----> 8\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred_scaled\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m      9\u001b[0m mini\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32780.873847\u001b[39m\n\u001b[1;32m     10\u001b[0m maxi\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m423444.390589\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:1052\u001b[0m, in \u001b[0;36mStandardScaler.inverse_transform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1051\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_std:\n\u001b[0;32m-> 1052\u001b[0m         X \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_\n\u001b[1;32m   1053\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n\u001b[1;32m   1054\u001b[0m         X \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_\n","\u001b[0;31mValueError\u001b[0m: non-broadcastable output operand with shape (23400,1) doesn't match the broadcast shape (23400,29)"],"ename":"ValueError","evalue":"non-broadcastable output operand with shape (23400,1) doesn't match the broadcast shape (23400,29)","output_type":"error"}]},{"cell_type":"code","source":"csv_file['Operational Energy']=y_pred_scaled","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:46:05.540588Z","iopub.execute_input":"2023-05-08T08:46:05.540998Z","iopub.status.idle":"2023-05-08T08:46:05.546754Z","shell.execute_reply.started":"2023-05-08T08:46:05.540968Z","shell.execute_reply":"2023-05-08T08:46:05.545576Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"csv_file.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:46:07.315244Z","iopub.execute_input":"2023-05-08T08:46:07.315704Z","iopub.status.idle":"2023-05-08T08:46:07.327350Z","shell.execute_reply.started":"2023-05-08T08:46:07.315659Z","shell.execute_reply":"2023-05-08T08:46:07.325977Z"},"trusted":true},"execution_count":64,"outputs":[{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"           submission id  Operational Energy\n0      Building_1_Town_1           -1.029256\n1    Building_100_Town_1           -0.937956\n2   Building_1000_Town_2           -1.404884\n3  Building_10000_Town_0            2.210037\n4  Building_10005_Town_2            0.377590","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>submission id</th>\n      <th>Operational Energy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Building_1_Town_1</td>\n      <td>-1.029256</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Building_100_Town_1</td>\n      <td>-0.937956</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Building_1000_Town_2</td>\n      <td>-1.404884</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Building_10000_Town_0</td>\n      <td>2.210037</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Building_10005_Town_2</td>\n      <td>0.377590</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"csv_file.to_csv(\"simple4.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T22:30:19.679200Z","iopub.execute_input":"2023-05-06T22:30:19.679552Z","iopub.status.idle":"2023-05-06T22:30:19.753618Z","shell.execute_reply.started":"2023-05-06T22:30:19.679523Z","shell.execute_reply":"2023-05-06T22:30:19.752511Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"markdown","source":"# # stop\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport xgboost as xgb\nfrom sklearn.model_selection import KFold\n\n# set up the KFold object\nn_folds = 5\nkf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n\n# initialize the model\nmodel = xgb.XGBRegressor(objective='reg:squarederror')\n\n# define the features and target\nX = train.drop(['Operational Energy'], axis=1)\ny = train['Operational Energy']\n\n# initialize the list to store the mean squared errors (MSEs)\nmse_list = []\n\n# loop over the folds\nfor train_index, val_index in kf.split(X):\n    \n    # split the data into training and validation sets\n    X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n    \n    # fit the model on the training data\n    model.fit(X_train_fold, y_train_fold)\n    \n    # make predictions on the validation data\n    y_pred_fold = model.predict(X_val_fold)\n    \n    # calculate the mean squared error\n    mse_fold = np.mean((y_pred_fold - y_val_fold)**2)\n    \n    # append the MSE to the list\n    mse_list.append(mse_fold)\n\n# calculate the mean and standard deviation of the MSEs\nmean_mse = np.mean(mse_list)\nstd_mse = np.std(mse_list)\n\nprint(\"Mean MSE: {:.2f}\".format(mean_mse))\nprint(\"Standard deviation of MSE: {:.2f}\".format(std_mse))\n","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:46:49.897938Z","iopub.execute_input":"2023-05-08T08:46:49.898367Z","iopub.status.idle":"2023-05-08T08:47:44.460820Z","shell.execute_reply.started":"2023-05-08T08:46:49.898336Z","shell.execute_reply":"2023-05-08T08:47:44.459967Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"Mean MSE: 10721374.51\nStandard deviation of MSE: 553000.97\n","output_type":"stream"}]},{"cell_type":"code","source":"y_pred_fold = model.predict(test)\ny_pred_fold\n","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:47:44.465002Z","iopub.execute_input":"2023-05-08T08:47:44.465725Z","iopub.status.idle":"2023-05-08T08:47:44.505331Z","shell.execute_reply.started":"2023-05-08T08:47:44.465689Z","shell.execute_reply":"2023-05-08T08:47:44.504525Z"},"trusted":true},"execution_count":67,"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"array([ 73984.1  , 106435.945,  90387.55 , ..., 223962.64 ,  62681.79 ,\n       198606.92 ], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"csv_file['Operational Energy']=y_pred_fold\ncsv_file.to_csv(\"simple6.csv\",index=False)\ncsv_file.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:47:57.022419Z","iopub.execute_input":"2023-05-08T08:47:57.022834Z","iopub.status.idle":"2023-05-08T08:47:57.101211Z","shell.execute_reply.started":"2023-05-08T08:47:57.022803Z","shell.execute_reply":"2023-05-08T08:47:57.099916Z"},"trusted":true},"execution_count":68,"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"           submission id  Operational Energy\n0      Building_1_Town_1        73984.101562\n1    Building_100_Town_1       106435.945312\n2   Building_1000_Town_2        90387.546875\n3  Building_10000_Town_0       342914.281250\n4  Building_10005_Town_2       240558.953125","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>submission id</th>\n      <th>Operational Energy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Building_1_Town_1</td>\n      <td>73984.101562</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Building_100_Town_1</td>\n      <td>106435.945312</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Building_1000_Town_2</td>\n      <td>90387.546875</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Building_10000_Town_0</td>\n      <td>342914.281250</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Building_10005_Town_2</td>\n      <td>240558.953125</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train=pd.read_csv(\"/kaggle/input/traintrain/Train.csv\")\ntest = pd.read_csv(\"/kaggle/input/testtest/Test (2).csv\")\ncsv_file = pd.DataFrame()\ncsv_file['submission id'] = test['building'] + '_Town_' + test['Town'].astype(str)\n\ncsv_file.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:51:00.535855Z","iopub.execute_input":"2023-05-08T08:51:00.536295Z","iopub.status.idle":"2023-05-08T08:51:01.393946Z","shell.execute_reply.started":"2023-05-08T08:51:00.536256Z","shell.execute_reply":"2023-05-08T08:51:01.392521Z"},"trusted":true},"execution_count":70,"outputs":[{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"           submission id\n0      Building_1_Town_1\n1    Building_100_Town_1\n2   Building_1000_Town_2\n3  Building_10000_Town_0\n4  Building_10005_Town_2","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>submission id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Building_1_Town_1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Building_100_Town_1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Building_1000_Town_2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Building_10000_Town_0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Building_10005_Town_2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\n\n\n\n\ntrain[\"random load mesures\"] = train[\"random load mesures\"].str.replace(\"'\",'\"')\ntest[\"random load mesures\"] = test[\"random load mesures\"].str.replace(\"'\",'\"')\ntrain['building'] = train['building'].str.replace(\"Building_\",\"\")\ntrain['building'] = train['building'].astype(int)\ntrain['File'] = train['File'].str.replace(\"Shape0_\",\"\")\ntrain['File'] = train['File'].astype(int)\n\ntest['building'] = test['building'].str.replace(\"Building_\",\"\")\ntest['building'] = test['building'].astype(int)\ntest['File'] = test['File'].str.replace(\"Shape0_\",\"\")\ntest['File'] = test['File'].astype(int)\n\nimport re \n\naddress = train['WWR']\n\nWWR = []\n\nfor i in address :\n    \n\n    values = re.findall(r'\\d+\\.\\d+',i)\n\n    float_value = [float(value) for value in values]\n\n    maxi = max(float_value)\n\n    WWR.append(maxi)\n\ntrain['WWR']= WWR\n\nimport re \n\naddress2 = test['WWR']\n\nWWR = []\n\nfor i in address2 :\n\n    values = re.findall(r'\\d+\\.\\d+',i)\n\n    float_value = [float(value) for value in values]\n\n    maxi = max(float_value)\n\n    WWR.append(maxi)\n\ntest['WWR']= WWR\n\nimport json\ncooling = []\nlights = []\nn=train.shape[0]\n# loop through the dataset\nfor i in range(n):\n    # extract the feature value (which is a dictionary)\n    feature_value = train['random load mesures'][i]\n    #print(feature_value)\n    feature=json.loads(feature_value)\n    values_list = list(feature.values())\n    # extract the values for Cooling and Lights from the dictionary\n    cooling_value = float(values_list[0].replace(\":C\",\"\"))\n    lights_value = float(values_list[1].replace(\":C\",\"\"))\n    \n    # add the values to the corresponding lists\n    cooling.append(cooling_value)\n    lights.append(lights_value)\n    \n# print the two l\n\ntrain[\"Coolings\"]=cooling\ntrain[\"Lights\"]=lights\n\n\ncooling2 = []\nlights2 = []\nn2=test.shape[0]\n# loop through the dataset\nfor i in range(n2):\n    # extract the feature value (which is a dictionary)\n    feature_value2 = test['random load mesures'][i]\n    #print(feature_value)\n    feature2=json.loads(feature_value2)\n    values_list2 = list(feature2.values())\n    # extract the values for Cooling and Lights from the dictionary\n    cooling_value2 = float(values_list2[0].replace(\":C\",\"\"))\n    lights_value2 = float(values_list2[1].replace(\":C\",\"\"))\n    \n    # add the values to the corresponding lists\n    cooling2.append(cooling_value2)\n    lights2.append(lights_value2)\n    \n# print the two l\n\ntest[\"Coolings\"]=cooling2\ntest[\"Lights\"]=lights2\n\ntrain=train.drop('random load mesures', axis=1)\ntrain=train.drop(['Permeability'], axis=1)\ntrain.head()\n\n\ntest=test.drop('random load mesures', axis=1)\ntest=test.drop(['Permeability'], axis=1)\ntest.head()\n\nimport numpy as np\nimport xgboost as xgb\nfrom sklearn.model_selection import KFold\n\n# set up the KFold object\nn_folds = 5\nkf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n\n# initialize the model\nmodel = xgb.XGBRegressor(objective='reg:squarederror')\n\n# define the features and target\nX = train.drop(['Operational Energy'], axis=1)\ny = train['Operational Energy']\n\n# initialize the list to store the mean squared errors (MSEs)\nmse_list = []\n\n# loop over the folds\nfor train_index, val_index in kf.split(X):\n    \n    # split the data into training and validation sets\n    X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n    \n    # fit the model on the training data\n    model.fit(X_train_fold, y_train_fold)\n    \n    # make predictions on the validation data\n    y_pred_fold = model.predict(X_val_fold)\n    \n    # calculate the mean squared error\n    mse_fold = np.mean((y_pred_fold - y_val_fold)**2)\n    \n    # append the MSE to the list\n    mse_list.append(mse_fold)\n\n# calculate the mean and standard deviation of the MSEs\nmean_mse = np.mean(mse_list)\nstd_mse = np.std(mse_list)\n\nprint(\"Mean MSE: {:.2f}\".format(mean_mse))\nprint(\"Standard deviation of MSE: {:.2f}\".format(std_mse))\n\ny_pred_fold = model.predict(test)\ny_pred_fold\n\n\ncsv_file1['Operational Energy']=y_pred_fold\ncsv_file1['Operational Energy']=csv_file['Operational Energy'].astype(int)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:51:01.395867Z","iopub.execute_input":"2023-05-08T08:51:01.396204Z","iopub.status.idle":"2023-05-08T08:51:55.340182Z","shell.execute_reply.started":"2023-05-08T08:51:01.396176Z","shell.execute_reply":"2023-05-08T08:51:55.339345Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"Mean MSE: 10721374.51\nStandard deviation of MSE: 553000.97\n","output_type":"stream"}]},{"cell_type":"code","source":"csv_file.to_csv(\"last11122.csv\",index=False)\ncsv_file.head()\n","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:52:08.453009Z","iopub.execute_input":"2023-05-08T08:52:08.453386Z","iopub.status.idle":"2023-05-08T08:52:08.510828Z","shell.execute_reply.started":"2023-05-08T08:52:08.453357Z","shell.execute_reply":"2023-05-08T08:52:08.509257Z"},"trusted":true},"execution_count":74,"outputs":[{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"           submission id  Operational Energy\n0      Building_1_Town_1               73984\n1    Building_100_Town_1              106435\n2   Building_1000_Town_2               90387\n3  Building_10000_Town_0              342914\n4  Building_10005_Town_2              240558","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>submission id</th>\n      <th>Operational Energy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Building_1_Town_1</td>\n      <td>73984</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Building_100_Town_1</td>\n      <td>106435</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Building_1000_Town_2</td>\n      <td>90387</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Building_10000_Town_0</td>\n      <td>342914</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Building_10005_Town_2</td>\n      <td>240558</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nimport re \nimport json\nimport xgboost as xgb\nfrom sklearn.model_selection import KFold\n\ndef preprocess(df):\n    # Replace single quotes with double quotes in \"random load mesures\" column\n    df[\"random load mesures\"] = df[\"random load mesures\"].str.replace(\"'\",'\"')\n    \n    # Remove prefix from building and file columns and convert to int\n    df['building'] = df['building'].str.replace(\"Building_\",\"\").astype(int)\n    df['File'] = df['File'].str.replace(\"Shape0_\",\"\").astype(int)\n    \n    # Extract WWR feature using regular expression\n    pattern = r'\\d+\\.\\d+'\n    wwr = df['WWR'].apply(lambda x: max([float(m) for m in re.findall(pattern, x)]))\n    df['WWR'] = wwr\n    \n    # Extract Cooling and Lights features using JSON\n    features = df['random load mesures'].apply(lambda x: json.loads(x))\n    cooling = features.apply(lambda x: float(x['Cooling'].replace(\":C\",\"\")))\n    lights = features.apply(lambda x: float(x['Lights'].replace(\":C\",\"\")))\n    df['Coolings'] = cooling\n    df['Lights'] = lights\n    \n    # Drop unnecessary columns\n    df = df.drop(['random load mesures', 'Permeability'], axis=1)\n    return df\n\n# Load train and test data\ntrain = pd.read_csv(\"/kaggle/input/traintrain/Train.csv\", dtype={'building':int, 'File':int})\ntest = pd.read_csv(\"/kaggle/input/testtest/Test (2).csv\", dtype={'building':int, 'File':int})\n\n# Preprocess train and test data\ntrain = preprocess(train)\ntest = preprocess(test)\n\n# Initialize the model\nmodel = xgb.XGBRegressor(objective='reg:squarederror')\n\n# Define the features and target\nX = train.drop(['Operational Energy'], axis=1)\ny = train['Operational Energy']\n\n# Set up the KFold object\nn_folds = 5\nkf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n\n# Initialize the list to store the mean squared errors (MSEs)\nmse_list = []\n\n# Loop over the folds\nfor train_index, val_index in kf.split(X):\n    \n    # Split the data into training and validation sets\n    X_train_fold, X_val_fold = X.iloc[train_index], X\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport json\nimport re\nimport xgboost as xgb\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\n# read the data with specified data types\ndtypes = {\n    'Building': 'int16',\n    'Shape': 'int16',\n    'WWR': 'float32',\n    'GlazingArea': 'float32',\n    'WallArea': 'float32',\n    'Orientation': 'int8',\n    'CoolingLoad': 'float32',\n    'HeatingLoad': 'float32',\n    'random load mesures': 'string',\n    'Permeability': 'float32'\n}\n\ntrain = pd.read_csv('/kaggle/input/traintrain/Train.csv', dtype=dtypes)\ntest = pd.read_csv('/kaggle/input/testtest/Test (2).csv', dtype=dtypes)\n\n# extract building and shape numbers from column names\ntrain.rename(columns=lambda x: re.sub(r'\\D', '', x), inplace=True)\ntest.rename(columns=lambda x: re.sub(r'\\D', '', x), inplace=True)\n\n# extract the maximum WWR value from the WWR column\ntrain['WWR'] = train['WWR'].apply(lambda x: max([float(i) for i in re.findall(r'\\d+\\.\\d+', x)]))\ntest['WWR'] = test['WWR'].apply(lambda x: max([float(i) for i in re.findall(r'\\d+\\.\\d+', x)]))\n\naddress = train['WWR']\nWWR = []\nfor i in address :\n    values = re.findall(r'\\d+\\.\\d+',i)\n    float_value = [float(value) for value in values]\n    maxi = max(float_value)\n    WWR.append(maxi)\ntrain['WWR']= WWR\n\nimport re \naddress2 = test['WWR']\nWWR = []\nfor i in address2 :\n    values = re.findall(r'\\d+\\.\\d+',i)\n    float_value = [float(value) for value in values]\n    maxi = max(float_value)\n    WWR.append(maxi)\ntest['WWR']= WWR\n\n\n# extract cooling and lighting values from the random load mesures column\ndef extract_feature_values(df):\n    df = pd.concat([df, pd.json_normalize(df['random load mesures'].apply(json.loads))], axis=1)\n    df['Cooling'] = df['Cooling'].str.replace(':C', '').astype('float32')\n    df['Lights'] = df['Lights'].str.replace(':C', '').astype('float32')\n    df = df.drop('random load mesures', axis=1)\n    return df\n\ntrain = extract_feature_values(train)\ntest = extract_feature_values(test)\n\n# drop the Permeability column\ntrain = train.drop('Permeability', axis=1)\ntest = test.drop('Permeability', axis=1)\n\n# standardize the data\nscaler = StandardScaler()\ntrain_scaled = scaler.fit_transform(train.drop('Operational Energy', axis=1))\ntest_scaled = scaler.transform(test)\n\n# apply PCA to reduce dimensionality\npca = PCA(n_components=10)\ntrain_pca = pca.fit_transform(train_scaled)\ntest_pca = pca.transform(test_scaled)\n\n# train XGBoost model with built-in cross-validation\nmodel = xgb.XGBRegressor(objective='reg:squarederror')\nparams = {\n    'n_estimators': [100, 500, 1000],\n    'learning_rate': [0.05, 0.1, 0.2],\n    'max_depth': [3, 5, 7],\n    'subsample': [0.5, 0.7, 0.9],\n    'colsample_bytree': [0.5, 0.7, 0.9],\n    'gamma': [0, 0.1, 0.2]\n}\n\nfrom sklearn.model_selection import GridSearchCV\n\ngrid = GridSearchCV(model, params, cv=5, verbose=3)\ngrid.fit(train_pca, train['Operational Energy'])\n\n# print best hyperparameters and score\nprint('Best hyperparameters:', grid.best_params_)\nprint('Best score:', grid.best_score_)\n\n# make predictions on test set using best model\nbest_model = grid.best_estimator_\npredictions = best_model.predict(test_pca)\n\n# save predictions to CSV file\nsubmission = pd.DataFrame({'Operational Energy': predictions})\nsubmission.to_csv('submission.csv', index=False)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-06T23:13:50.341993Z","iopub.execute_input":"2023-05-06T23:13:50.342511Z","iopub.status.idle":"2023-05-06T23:13:50.691138Z","shell.execute_reply.started":"2023-05-06T23:13:50.342452Z","shell.execute_reply":"2023-05-06T23:13:50.689299Z"},"trusted":true},"execution_count":114,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:1124\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Cannot cast array data from dtype('O') to dtype('float32') according to the rule 'safe'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[114], line 24\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# read the data with specified data types\u001b[39;00m\n\u001b[1;32m     11\u001b[0m dtypes \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBuilding\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint16\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShape\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint16\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPermeability\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     22\u001b[0m }\n\u001b[0;32m---> 24\u001b[0m train \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/traintrain/Train.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/testtest/Test (2).csv\u001b[39m\u001b[38;5;124m'\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtypes)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# extract building and shape numbers from column names\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1778\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1771\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m     (\n\u001b[1;32m   1775\u001b[0m         index,\n\u001b[1;32m   1776\u001b[0m         columns,\n\u001b[1;32m   1777\u001b[0m         col_dict,\n\u001b[0;32m-> 1778\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1779\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1780\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1782\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:230\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 230\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    232\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:808\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:890\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:1037\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:1130\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: could not convert string to float: '(0.771636962890625,0.436004638671875,0.574652099609375,0.193316650390625)'"],"ename":"ValueError","evalue":"could not convert string to float: '(0.771636962890625,0.436004638671875,0.574652099609375,0.193316650390625)'","output_type":"error"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nimport re \nimport json\nimport xgboost as xgb\nfrom sklearn.model_selection import KFold\n\ndef preprocess(df):\n    # Replace single quotes with double quotes in \"random load mesures\" column\n    df[\"random load mesures\"] = df[\"random load mesures\"].str.replace(\"'\",'\"')\n    \n    # Remove prefix from building and file columns and convert to int\n    df['building'] = df['building'].str.replace(\"Building_\",\"\").astype(int)\n    df['File'] = df['File'].str.replace(\"Shape0_\",\"\").astype(int)\n    \n    # Extract WWR feature using regular expression\n    pattern = r'\\d+\\.\\d+'\n    wwr = df['WWR'].apply(lambda x: max([float(m) for m in re.findall(pattern, x)]))\n    df['WWR'] = wwr\n    \n    # Extract Cooling and Lights features using JSON\n    features = df['random load mesures'].apply(lambda x: json.loads(x))\n    cooling = features.apply(lambda x: float(x['Cooling'].replace(\":C\",\"\")))\n    lights = features.apply(lambda x: float(x['Lights'].replace(\":C\",\"\")))\n    df['Coolings'] = cooling\n    df['Lights'] = lights\n    \n    # Drop unnecessary columns\n    df = df.drop(['random load mesures', 'Permeability'], axis=1)\n    return df\n\n# Load train and test data\ntrain = pd.read_csv(\"/kaggle/input/traintrain/Train.csv\")\ntest = pd.read_csv(\"/kaggle/input/testtest/Test (2).csv\")\n\n# Preprocess train and test data\ntrain = preprocess(train)\ntest = preprocess(test)\n\n# Initialize the model\nmodel = xgb.XGBRegressor(objective='reg:squarederror')\n\n# Define the features and target\nX = train.drop(['Operational Energy'], axis=1)\ny = train['Operational Energy']\n\n# Set up the KFold object\nn_folds = 5\nkf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n\n# Initialize the list to store the mean squared errors (MSEs)\nmse_list = []\n\n# Loop over the folds\nfor train_index, val_index in kf.split(X):\n    \n    # Split the data into training and validation sets\n    X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n    \n    # Scale the data using StandardScaler\n    scaler = StandardScaler()\n    X_train_fold_scaled = scaler.fit_transform(X_train_fold)\n    X_val_fold_scaled = scaler.transform(X_val_fold)\n    \n    # Apply PCA to reduce dimensionality\n    pca = PCA(n_components=10)\n    X_train_fold_pca = pca.fit_transform(X_train_fold_scaled)\n    X_val_fold_pca = pca.transform(X_val_fold_scaled)\n    \n    # Train the model\n    model.fit(X_train_fold_pca, y_train_fold)\n    \n    # Make predictions on the validation set and calculate MSE\n    y_pred = model.predict(X_val_fold_pca)\n    mse = np.mean((y_val_fold - y_pred)**2)\n    \n    # Append the MSE to the list\n    mse_list.append(mse)\n    \n# Print the mean of the MSEs\nprint(\"Mean MSE:\", np.mean(mse_list))\n","metadata":{"execution":{"iopub.status.busy":"2023-05-07T00:11:22.632311Z","iopub.execute_input":"2023-05-07T00:11:22.632747Z","iopub.status.idle":"2023-05-07T00:11:57.479150Z","shell.execute_reply.started":"2023-05-07T00:11:22.632714Z","shell.execute_reply":"2023-05-07T00:11:57.478181Z"},"trusted":true},"execution_count":142,"outputs":[{"name":"stdout","text":"Mean MSE: 1074205429.7292588\n","output_type":"stream"}]},{"cell_type":"code","source":"y_pris=scaler.fit_transform(test)\ny_pris=pca.transform(y_pris)\ny_pris = model.predict(y_pris)\ny_pris","metadata":{"execution":{"iopub.status.busy":"2023-05-07T00:11:57.483945Z","iopub.execute_input":"2023-05-07T00:11:57.486093Z","iopub.status.idle":"2023-05-07T00:11:57.602377Z","shell.execute_reply.started":"2023-05-07T00:11:57.486055Z","shell.execute_reply":"2023-05-07T00:11:57.601426Z"},"trusted":true},"execution_count":143,"outputs":[{"execution_count":143,"output_type":"execute_result","data":{"text/plain":"array([123521.39 , 123209.16 ,  89800.625, ..., 202099.97 ,  73309.44 ,\n       170271.3  ], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"csv_file=pd.read_csv(\"/kaggle/input/simple/SampleSubmission.csv\")\ncsv_file['Operational Energy']=y_pris\ncsv_file.to_csv(\"simple7.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-07T00:11:57.603534Z","iopub.execute_input":"2023-05-07T00:11:57.603848Z","iopub.status.idle":"2023-05-07T00:11:57.698190Z","shell.execute_reply.started":"2023-05-07T00:11:57.603821Z","shell.execute_reply":"2023-05-07T00:11:57.697023Z"},"trusted":true},"execution_count":144,"outputs":[]},{"cell_type":"code","source":"importances = model.feature_importances_\n\n# Sort feature importances in descending order\nsorted_importances = sorted(zip(importances, X.columns), reverse=True)\n\n# Print the feature importances\nfor importance, feature in sorted_importances:\n    print(f\"{feature}: {importance}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-05-07T00:11:57.700544Z","iopub.execute_input":"2023-05-07T00:11:57.700901Z","iopub.status.idle":"2023-05-07T00:11:57.708783Z","shell.execute_reply.started":"2023-05-07T00:11:57.700872Z","shell.execute_reply":"2023-05-07T00:11:57.707670Z"},"trusted":true},"execution_count":145,"outputs":[{"name":"stdout","text":"building: 0.5055546760559082\nFile: 0.2994295656681061\nEUI: 0.07109592109918594\nCooling Setpoint: 0.03435992822051048\nCooling COP: 0.02574128285050392\nOperating Hours: 0.01791604980826378\nWWR: 0.012049667537212372\nInternal Floor Rt: 0.011782154440879822\nInternal Wall Rt: 0.011304556392133236\nEquipment Heat Gain: 0.010766172781586647\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load train and test data\ntrain = pd.read_csv(\"/kaggle/input/traintrain/Train.csv\")\ntest = pd.read_csv(\"/kaggle/input/testtest/Test (2).csv\")\n\n# Preprocess train and test data\ntrain = preprocess(train)\ntest = preprocess(test)\n\n# Initialize the model\nmodel = xgb.XGBRegressor(objective='reg:squarederror')\n\n# Define the features and target\nX = train.drop(['Operational Energy'], axis=1)\ny = train['Operational Energy']\n\n# Feature selection using XGBoost\nmodel.fit(X, y)\nimportance_scores = model.feature_importances_\nfeature_importances = dict(zip(X.columns, importance_scores))\ntop_5_features = sorted(feature_importances, key=feature_importances.get, reverse=True)[:5]\n\n# Select only the top 5 features\nX = X[top_5_features]\ntest = test[top_5_features]\n\n# Set up the KFold object\nn_folds = 5\nkf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n\n# Initialize the list to store the mean squared errors (MSEs)\nmse_list = []\n\n# Loop over the folds\nfor train_index, val_index in kf.split(X):\n    \n    # Split the data into training and validation sets\n    X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n\n    # Scale the features\n    scaler = StandardScaler()\n    X_train_fold = scaler.fit_transform(X_train_fold)\n    X_val_fold = scaler.transform(X_val_fold)\n    \n    # Reduce dimensionality using PCA\n    pca = PCA(n_components=2)\n    X_train_fold = pca.fit_transform(X_train_fold)\n    X_val_fold = pca.transform(X_val_fold)\n\n    # Train the model and predict on the validation set\n    model.fit(X_train_fold, y_train_fold)\n    y_pred = model.predict(X_val_fold)\n\n    # Compute the mean squared error\n    mse = np.mean((y_val_fold - y_pred)**2)\n    mse_list.append(mse)\n\n# Compute the average mean squared error over the folds\navg_mse = np.mean(mse_list)\nprint(\"Average MSE:\", avg_mse)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-07T00:11:57.710392Z","iopub.execute_input":"2023-05-07T00:11:57.710804Z","iopub.status.idle":"2023-05-07T00:12:22.975374Z","shell.execute_reply.started":"2023-05-07T00:11:57.710774Z","shell.execute_reply":"2023-05-07T00:12:22.974518Z"},"trusted":true},"execution_count":146,"outputs":[{"name":"stdout","text":"Average MSE: 1517136840.3895955\n","output_type":"stream"}]},{"cell_type":"code","source":"y_pris1=scaler.fit_transform(test)\ny_pris1=pca.transform(y_pris1)\ny_pris1 = model.predict(y_pris1)\ny_pris1","metadata":{"execution":{"iopub.status.busy":"2023-05-07T00:12:22.979825Z","iopub.execute_input":"2023-05-07T00:12:22.980901Z","iopub.status.idle":"2023-05-07T00:12:23.021843Z","shell.execute_reply.started":"2023-05-07T00:12:22.980854Z","shell.execute_reply":"2023-05-07T00:12:23.020756Z"},"trusted":true},"execution_count":147,"outputs":[{"execution_count":147,"output_type":"execute_result","data":{"text/plain":"array([115691.836, 107701.83 ,  83919.64 , ..., 253284.1  ,  92820.85 ,\n       168434.28 ], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"csv_file=pd.read_csv(\"/kaggle/input/simple/SampleSubmission.csv\")\ncsv_file['Operational Energy']=y_pris1\ncsv_file.to_csv(\"simple9.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-07T00:12:23.025699Z","iopub.execute_input":"2023-05-07T00:12:23.028029Z","iopub.status.idle":"2023-05-07T00:12:23.110446Z","shell.execute_reply.started":"2023-05-07T00:12:23.027991Z","shell.execute_reply":"2023-05-07T00:12:23.109315Z"},"trusted":true},"execution_count":148,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import BaggingRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\ntrain = pd.read_csv(\"/kaggle/input/traintrain/Train.csv\")\ntest = pd.read_csv(\"/kaggle/input/testtest/Test (2).csv\")\n\ntrain=preprocess(train)\ntest=preprocess(test)\n\n# Assuming you have your feature matrix X and target variable y\nX = train.drop(['Operational Energy'], axis=1)\ny = train['Operational Energy']\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Initialize the base estimator\nbase_estimator = GradientBoostingRegressor()\n\n# Initialize the bagging regressor\nbagging = BaggingRegressor(base_estimator=base_estimator, n_estimators=10, random_state=42)\n\n# Fit the bagging regressor to the training data\nbagging.fit(X_train, y_train)\n\n# Make predictions on the test data\ny_pred = bagging.predict(X_test)\n\n# Evaluate the model\nmse = mean_squared_error(y_test, y_pred)\nprint(\"Mean Squared Error:\", mse)","metadata":{"execution":{"iopub.status.busy":"2023-05-07T00:13:27.123110Z","iopub.execute_input":"2023-05-07T00:13:27.123504Z","iopub.status.idle":"2023-05-07T00:18:13.179326Z","shell.execute_reply.started":"2023-05-07T00:13:27.123460Z","shell.execute_reply":"2023-05-07T00:18:13.178256Z"},"trusted":true},"execution_count":150,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Mean Squared Error: 46236874.49956753\n","output_type":"stream"}]},{"cell_type":"code","source":"y_predddding = bagging.predict(test)\ny_predddding","metadata":{"execution":{"iopub.status.busy":"2023-05-07T00:18:13.181231Z","iopub.execute_input":"2023-05-07T00:18:13.181563Z","iopub.status.idle":"2023-05-07T00:18:13.711661Z","shell.execute_reply.started":"2023-05-07T00:18:13.181537Z","shell.execute_reply":"2023-05-07T00:18:13.710609Z"},"trusted":true},"execution_count":151,"outputs":[{"execution_count":151,"output_type":"execute_result","data":{"text/plain":"array([ 72081.95790779, 106476.79049582,  88765.45820917, ...,\n       227919.80029233,  61737.82360946, 182216.35779605])"},"metadata":{}}]},{"cell_type":"code","source":"csv_file=pd.read_csv(\"/kaggle/input/simple/SampleSubmission.csv\")\ncsv_file['Operational Energy']=y_predddding\ncsv_file.to_csv(\"simplesimpled++.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-07T00:18:29.374638Z","iopub.execute_input":"2023-05-07T00:18:29.375005Z","iopub.status.idle":"2023-05-07T00:18:29.466696Z","shell.execute_reply.started":"2023-05-07T00:18:29.374978Z","shell.execute_reply":"2023-05-07T00:18:29.465544Z"},"trusted":true},"execution_count":153,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}