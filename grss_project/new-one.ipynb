{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix as cm\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.losses import *\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.metrics import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.applications import *\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom PIL import Image, ImageEnhance\n\n# For Data Visualization      \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Miscellaneous\nfrom tqdm import tqdm\nimport time\nimport os\nimport random\nimport pandas as pd\nfrom IPython import display\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-14T14:26:57.792279Z","iopub.execute_input":"2022-05-14T14:26:57.792607Z","iopub.status.idle":"2022-05-14T14:27:03.903084Z","shell.execute_reply.started":"2022-05-14T14:26:57.792529Z","shell.execute_reply":"2022-05-14T14:27:03.902332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = '/kaggle/input/binary-cropped-crown-of-thorns-dataset/'\n\nunique_labels = os.listdir(data_dir)\nall_paths = []\nall_labels = []\n\nfor label in os.listdir(data_dir):\n    for image in os.listdir(data_dir+label):\n        all_paths.append(data_dir+label+'/'+image)\n        all_labels.append(label)\n\nall_paths, all_labels = shuffle(all_paths, all_labels)\nx_train_paths, x_val_paths, y_train, y_val = train_test_split(all_paths, all_labels, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T14:27:03.906376Z","iopub.execute_input":"2022-05-14T14:27:03.906960Z","iopub.status.idle":"2022-05-14T14:27:04.499649Z","shell.execute_reply.started":"2022-05-14T14:27:03.906917Z","shell.execute_reply":"2022-05-14T14:27:04.498926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model = MobileNetV2(input_shape=(128, 128, 3), weights='imagenet', include_top=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T14:27:04.502861Z","iopub.execute_input":"2022-05-14T14:27:04.503057Z","iopub.status.idle":"2022-05-14T14:27:08.229014Z","shell.execute_reply.started":"2022-05-14T14:27:04.503032Z","shell.execute_reply":"2022-05-14T14:27:08.228311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def augment_image(image):\n    if random.uniform(0,1)>0.5:\n        image = np.fliplr(image)\n    image = Image.fromarray(np.uint8(image))\n    image = ImageEnhance.Brightness(image).enhance(random.uniform(0.6,1.4))\n    image = ImageEnhance.Contrast(image).enhance(random.uniform(0.6,1.4))\n    image = ImageEnhance.Color(image).enhance(random.uniform(0.6,1.4))\n    image = ImageEnhance.Sharpness(image).enhance(random.uniform(0.6,1.4))\n    return image\ndef open_images(paths, augment=True):\n    images = []\n    for path in paths:\n        image = load_img(path, target_size=(128,128))\n        image = np.array(image)\n        if augment:\n            image = augment_image(image)\n        image = np.array(image)/255.0\n        images.append(image)\n    return np.array(images)\n\ndef encode_label(labels):\n    encoded = []\n    for x in labels:\n        encoded.append(unique_labels.index(x))\n    return np.array(encoded)\n\ndef decode_label(labels):\n    decoded = []\n    for x in labels:\n        decoded.append(unique_labels[x])\n    return np.array(decoded)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-14T14:27:08.231186Z","iopub.execute_input":"2022-05-14T14:27:08.231427Z","iopub.status.idle":"2022-05-14T14:27:08.242293Z","shell.execute_reply.started":"2022-05-14T14:27:08.231393Z","shell.execute_reply":"2022-05-14T14:27:08.241581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x=open_images(x_train_paths[0:7000])\nx.shape\ny=encode_label(y_train[0:7000])","metadata":{"execution":{"iopub.status.busy":"2022-05-14T14:27:08.243250Z","iopub.execute_input":"2022-05-14T14:27:08.243812Z","iopub.status.idle":"2022-05-14T14:27:42.145709Z","shell.execute_reply.started":"2022-05-14T14:27:08.243774Z","shell.execute_reply":"2022-05-14T14:27:42.144921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Input(shape=(128,128,3)))\nmodel.add(base_model)\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Dropout(0.25))\nmodel.add(Dense(128,activation='relu'))\nmodel.add(Dropout(0.05))\nmodel.add(Dense(64,activation='relu'))\nmodel.add(Dropout(0.15))\nmodel.add(Dense(len(unique_labels),activation='softmax'))\nmodel.summary()\nkeras.utils.plot_model(model, show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T15:05:29.607393Z","iopub.execute_input":"2022-05-14T15:05:29.608331Z","iopub.status.idle":"2022-05-14T15:05:30.194306Z","shell.execute_reply.started":"2022-05-14T15:05:29.608289Z","shell.execute_reply":"2022-05-14T15:05:30.193505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T14:27:43.494713Z","iopub.execute_input":"2022-05-14T14:27:43.495272Z","iopub.status.idle":"2022-05-14T14:27:44.282585Z","shell.execute_reply.started":"2022-05-14T14:27:43.495229Z","shell.execute_reply":"2022-05-14T14:27:44.281882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(data_dir)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T14:27:44.283853Z","iopub.execute_input":"2022-05-14T14:27:44.284182Z","iopub.status.idle":"2022-05-14T14:27:44.289755Z","shell.execute_reply.started":"2022-05-14T14:27:44.284143Z","shell.execute_reply":"2022-05-14T14:27:44.289056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport pandas as pd\n\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    data_dir,\n    target_size=(150, 150),\n    batch_size=32,\n    class_mode='binary')\n\nvalidation_generator = test_datagen.flow_from_directory(\n    data_dir,\n    target_size=(150, 150),\n    batch_size=32,\n    class_mode='binary')","metadata":{"execution":{"iopub.status.busy":"2022-05-14T14:27:44.291002Z","iopub.execute_input":"2022-05-14T14:27:44.291385Z","iopub.status.idle":"2022-05-14T14:27:55.490859Z","shell.execute_reply.started":"2022-05-14T14:27:44.291352Z","shell.execute_reply":"2022-05-14T14:27:55.490083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=Adam(learning_rate=0.000175),\n              loss='sparse_categorical_crossentropy',\n              metrics=['sparse_categorical_accuracy'])\nhistory = model.fit(\n    x_train,y_train,\n    validation_data=(x_val,y_val),\n    batch_size=32,\n    epochs=15  \n)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T14:56:52.629633Z","iopub.execute_input":"2022-05-14T14:56:52.629903Z","iopub.status.idle":"2022-05-14T15:00:21.580466Z","shell.execute_reply.started":"2022-05-14T14:56:52.629871Z","shell.execute_reply":"2022-05-14T15:00:21.579669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs=15\nplt.figure(figsize=(8,8))\nplt.grid(True)\nplt.plot(history.history['val_sparse_categorical_accuracy'], '.g-', linewidth=2)\nplt.plot(history.history['loss'], '.r-', linewidth=2)\nplt.title('Model Training History')\nplt.xlabel('epoch')\nplt.xticks([x for x in range(epochs)])\nplt.legend(['Accuracy', 'Loss'], loc='upper left', bbox_to_anchor=(1, 1))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-14T15:00:47.524426Z","iopub.execute_input":"2022-05-14T15:00:47.525029Z","iopub.status.idle":"2022-05-14T15:00:47.752034Z","shell.execute_reply.started":"2022-05-14T15:00:47.524990Z","shell.execute_reply":"2022-05-14T15:00:47.751361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom tensorflow.keras.preprocessing import image as image_utils\nfrom tensorflow.keras.applications.imagenet_utils import preprocess_input\ncots='../input/binary-cropped-crown-of-thorns-dataset/cots_crops/cotscrop-video_0-1000-0.jpg'\nnot_cots='../input/newdataset/pic8.png'\ndef show_image(image_path):\n    image = mpimg.imread(image_path)\n    plt.imshow(image)\n\ndef make_predictions(image_path):\n    show_image(image_path)\n    image = image_utils.load_img(image_path, target_size=(128, 128))\n    image = image_utils.img_to_array(image)\n    image = image.reshape(1, 128, 128, 3)\n    image = preprocess_input(image)\n    preds = model.predict(image)\n    return preds\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-05-14T15:04:27.077273Z","iopub.execute_input":"2022-05-14T15:04:27.077554Z","iopub.status.idle":"2022-05-14T15:04:27.084321Z","shell.execute_reply.started":"2022-05-14T15:04:27.077505Z","shell.execute_reply":"2022-05-14T15:04:27.083605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_image(cots)\nmake_predictions(cots)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T15:04:29.761103Z","iopub.execute_input":"2022-05-14T15:04:29.761649Z","iopub.status.idle":"2022-05-14T15:04:30.003037Z","shell.execute_reply.started":"2022-05-14T15:04:29.761614Z","shell.execute_reply":"2022-05-14T15:04:30.002347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_image(not_cots)\nmake_predictions(not_cots)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T15:04:10.810890Z","iopub.execute_input":"2022-05-14T15:04:10.811155Z","iopub.status.idle":"2022-05-14T15:04:11.126325Z","shell.execute_reply.started":"2022-05-14T15:04:10.811127Z","shell.execute_reply":"2022-05-14T15:04:11.125680Z"},"trusted":true},"execution_count":null,"outputs":[]}]}