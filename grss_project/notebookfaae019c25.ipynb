{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix as cm\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.losses import *\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.metrics import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.applications import *\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom PIL import Image, ImageEnhance\n\n# For Data Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Miscellaneous\nfrom tqdm import tqdm\nimport time\nimport os\nimport random\nimport pandas as pd\nfrom IPython import display\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-06T21:56:18.958801Z","iopub.execute_input":"2022-05-06T21:56:18.960038Z","iopub.status.idle":"2022-05-06T21:56:26.264842Z","shell.execute_reply.started":"2022-05-06T21:56:18.959870Z","shell.execute_reply":"2022-05-06T21:56:26.264173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = '/kaggle/input/binary-cropped-crown-of-thorns-dataset/'\nunique_labels = os.listdir(data_dir)\nall_paths = []\nall_labels = []\n\nfor label in os.listdir(data_dir):\n    for image in os.listdir(data_dir+label):\n        all_paths.append(data_dir+label+'/'+image)\n        all_labels.append(label)\n\nall_paths, all_labels = shuffle(all_paths, all_labels)\nx_train_paths, x_val_paths, y_train, y_val = train_test_split(all_paths, all_labels, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T21:56:26.266523Z","iopub.execute_input":"2022-05-06T21:56:26.267005Z","iopub.status.idle":"2022-05-06T21:56:26.836557Z","shell.execute_reply.started":"2022-05-06T21:56:26.266963Z","shell.execute_reply":"2022-05-06T21:56:26.835865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model = MobileNetV2(input_shape=(128, 128, 3), weights='imagenet', include_top=False)\ndef open_images(paths, augment=False):\n    images = []\n    for path in paths:\n        image = load_img(path, target_size=(128,128))\n        image = np.array(image)\n        if augment:\n            image = augment_image(image)\n        image = np.array(image)/255.0\n        images.append(image)\n    return np.array(images)\n\ndef encode_label(labels):\n    encoded = []\n    for x in labels:\n        encoded.append(unique_labels.index(x))\n    return np.array(encoded)\n\ndef decode_label(labels):\n    decoded = []\n    for x in labels:\n        decoded.append(unique_labels[x])\n    return np.array(decoded)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-06T21:56:26.838062Z","iopub.execute_input":"2022-05-06T21:56:26.838554Z","iopub.status.idle":"2022-05-06T21:56:28.248798Z","shell.execute_reply.started":"2022-05-06T21:56:26.838509Z","shell.execute_reply":"2022-05-06T21:56:28.247734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x=open_images(x_train_paths[0:10000])\nx.shape\ny1=encode_label(y_train[0:10000])","metadata":{"execution":{"iopub.status.busy":"2022-05-06T21:56:28.250605Z","iopub.execute_input":"2022-05-06T21:56:28.250827Z","iopub.status.idle":"2022-05-06T21:57:37.452649Z","shell.execute_reply.started":"2022-05-06T21:56:28.250799Z","shell.execute_reply":"2022-05-06T21:57:37.451615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\ny = tf.keras.utils.to_categorical(y1, num_classes= 12)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-06T21:57:37.453784Z","iopub.execute_input":"2022-05-06T21:57:37.454022Z","iopub.status.idle":"2022-05-06T21:57:37.459068Z","shell.execute_reply.started":"2022-05-06T21:57:37.453994Z","shell.execute_reply":"2022-05-06T21:57:37.457985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Input(shape=(128,128,3)))\nmodel.add(base_model)\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Dense(512,activation='relu'))\nmodel.add(Dense(256,activation='relu'))\nmodel.add(Dense(len(unique_labels),activation='softmax'))\nmodel.summary()\nkeras.utils.plot_model(model, show_shapes=True)\nx_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-06T21:57:37.460431Z","iopub.execute_input":"2022-05-06T21:57:37.460657Z","iopub.status.idle":"2022-05-06T21:57:40.654799Z","shell.execute_reply.started":"2022-05-06T21:57:37.460631Z","shell.execute_reply":"2022-05-06T21:57:40.653768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(\n        rescale=1 / 255.0,\n        rotation_range=20,\n        zoom_range=0.05,\n        width_shift_range=0.05,\n        height_shift_range=0.05,\n        shear_range=0.05,\n        horizontal_flip=True,\n        fill_mode=\"nearest\",\n        validation_split=0.20)\ntest_datagen = ImageDataGenerator(rescale=1 / 255.0)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T21:57:40.656507Z","iopub.execute_input":"2022-05-06T21:57:40.656773Z","iopub.status.idle":"2022-05-06T21:57:40.663714Z","shell.execute_reply.started":"2022-05-06T21:57:40.656741Z","shell.execute_reply":"2022-05-06T21:57:40.662705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 8\ntrain_generator = train_datagen.flow_from_dataframe(\n    dataframe=x,\n    directory=x_train_paths,\n    x_col=\"img_code\",\n    y_col=\"target\",\n    target_size=(100, 100),\n    batch_size=batch_size,\n    class_mode=\"categorical\",\n    subset='training',\n    shuffle=True,\n    seed=42\n)\nvalid_generator = train_datagen.flow_from_dataframe(\n    dataframe=train_df,\n    directory=y,\n    x_col=\"img_code\",\n    y_col=\"target\",\n    target_size=(100, 100),\n    batch_size=batch_size,\n    class_mode=\"categorical\",\n    subset='validation',\n    shuffle=True,\n    seed=42\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-06T21:57:40.665049Z","iopub.execute_input":"2022-05-06T21:57:40.665307Z","iopub.status.idle":"2022-05-06T21:57:43.609257Z","shell.execute_reply.started":"2022-05-06T21:57:40.665278Z","shell.execute_reply":"2022-05-06T21:57:43.605845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=Adam(learning_rate=0.000175),\n              loss='sparse_categorical_crossentropy',\n              metrics=['sparse_categorical_accuracy'])\n#steps = int(len(x_train_paths)/batch_size)\n#epochs = 6\n#batch_size=32\nhistory = model.fit(\n    x_train,y_train,\n    validation_data=(x_val,y_val),\n    batch_size=32,\n    epochs=10\n    \n)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T21:57:43.610571Z","iopub.status.idle":"2022-05-06T21:57:43.610995Z","shell.execute_reply.started":"2022-05-06T21:57:43.610795Z","shell.execute_reply":"2022-05-06T21:57:43.610814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs=10\nplt.figure(figsize=(8,8))\nplt.grid(True)\nplt.plot(history.history['val_sparse_categorical_accuracy'], '.g-', linewidth=2)\nplt.plot(history.history['loss'], '.r-', linewidth=2)\nplt.title('Model Training History')\nplt.xlabel('epoch')\nplt.xticks([x for x in range(epochs)])\nplt.legend(['Accuracy', 'Loss'], loc='upper left', bbox_to_anchor=(1, 1))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-06T21:57:43.612112Z","iopub.status.idle":"2022-05-06T21:57:43.612399Z","shell.execute_reply.started":"2022-05-06T21:57:43.612241Z","shell.execute_reply":"2022-05-06T21:57:43.612257Z"},"trusted":true},"execution_count":null,"outputs":[]}]}